{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = '<API_KEY>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content='デ, ラ トーレ，マルティン ア\ttranslate to english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=api_key)\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "response = model.generate_content(content)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working python code to find the total cost for the request and response for API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#working python code to find the total cost for the request and response\n",
    "\n",
    "import requests\n",
    "\n",
    "def calculate_gemini_cost(input_tokens, output_tokens, model):\n",
    "    pricing = {\n",
    "        \"Gemini 1.5 Pro\": {\n",
    "            \"input\": 0.50 / 1000000,\n",
    "            \"output\": 1.50 / 1000000\n",
    "        },\n",
    "        \"Gemini 1.5 Flash\": {\n",
    "            \"input\": 0.075 / 1000000,\n",
    "            \"output\": 0.30 / 1000000\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if model not in pricing:\n",
    "        raise ValueError(\"Invalid model name. Choose either 'Gemini 1.5 Pro' or 'Gemini 1.5 Flash'.\")\n",
    "\n",
    "    input_cost_per_token = pricing[model][\"input\"]\n",
    "    output_cost_per_token = pricing[model][\"output\"]\n",
    "\n",
    "    total_cost = (input_tokens * input_cost_per_token) + (output_tokens * output_cost_per_token)\n",
    "    return total_cost\n",
    "\n",
    "def call_gemini_api(api_key, prompt, model):\n",
    "    endpoint = f\"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}\"\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = {\n",
    "        \"contents\": [{\"parts\": [{\"text\": prompt}]}]\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(endpoint, headers=headers, json=data)\n",
    "        response.raise_for_status()\n",
    "        # print(\"Raw response from API:\", response.json())\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    api_key = \"AIzaSyD_aSCCzpf0os_jAyzb_H-8SCfUUk7Q8Bk\"\n",
    "    prompt = input(\"Enter your prompt: \")\n",
    "    model = \"gemini-1.5-pro-latest\"\n",
    "    # model= \"gemini-1.5-flash\"\n",
    "    response = call_gemini_api(api_key, prompt, model)\n",
    "    if response is None:\n",
    "        return\n",
    "    usage_metadata = response.get(\"usageMetadata\", {})\n",
    "    input_tokens = usage_metadata.get(\"promptTokenCount\", 0)\n",
    "    output_tokens = usage_metadata.get(\"candidatesTokenCount\", 0)\n",
    "\n",
    "    output_text = response.get(\"candidates\", [{}])[0].get(\"content\", {}).get(\"parts\", [{}])[0].get(\"text\", \"\")\n",
    "    print('\\nresponse',output_text)\n",
    "    total_cost = calculate_gemini_cost(input_tokens, output_tokens, \"Gemini 1.5 Pro\")\n",
    "\n",
    "    print(f\"Input tokens: {input_tokens}\")\n",
    "    print(f\"Output tokens: {output_tokens}\")\n",
    "    print(f\"Total cost for the request and response using Gemini 1.5 Pro: ${total_cost:.6f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python code to find the total cost for the request and response for \"google.generativeai as genai\" module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python code to find the total cost for the request and response for \"google.generativeai as genai\" module\n",
    "\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "def get_token_count(text):\n",
    "    \"\"\"\n",
    "    Simple token count function that counts words in a text.\n",
    "    You can modify this for more sophisticated token counting if needed.\n",
    "    \"\"\"\n",
    "    return len(text.split())\n",
    "\n",
    "def calculate_gemini_cost(input_tokens, output_tokens, model):\n",
    "    \"\"\"\n",
    "    Calculate the cost of the Gemini response based on the number of tokens used.\n",
    "    \"\"\"\n",
    "    pricing = {\n",
    "        \"Gemini 1.5 Pro\": {\n",
    "            \"input\": 0.00125 / 1000,  \n",
    "            \"output\": 0.00375 / 1000 \n",
    "        },\n",
    "        \"Gemini 1.5 Flash\": {\n",
    "            \"input\": 0.00001875 / 1000,\n",
    "            \"output\": 0.000075 / 1000    \n",
    "        }\n",
    "    }\n",
    "\n",
    "    if model not in pricing:\n",
    "        raise ValueError(\"Invalid model name. Choose either 'Gemini 1.5 Pro' or 'Gemini 1.5 Flash'.\")\n",
    "\n",
    "    input_cost_per_token = pricing[model][\"input\"]\n",
    "    output_cost_per_token = pricing[model][\"output\"]\n",
    "\n",
    "    total_cost = (input_tokens * input_cost_per_token) + (output_tokens * output_cost_per_token)\n",
    "    return total_cost\n",
    "\n",
    "def main():\n",
    "    genai.configure(api_key=os.environ['GEMINI_API_KEY'])\n",
    "    model_name = 'gemini-1.5-pro'\n",
    "    # model_name = 'gemini-1.5-flash'\n",
    "    model = genai.GenerativeModel(model_name=model_name)\n",
    "    prompt = input(\"Enter your prompt: \")\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        print(\"Response text:\", response.text)\n",
    "        input_tokens = get_token_count(prompt)\n",
    "        output_tokens = get_token_count(response.text)\n",
    "\n",
    "        total_cost = calculate_gemini_cost(input_tokens, output_tokens, \"Gemini 1.5 Pro\")\n",
    "\n",
    "        print(f\"Input tokens: {input_tokens} | Cost for input: ${input_tokens * 0.00125 / 1000:.6f}\")\n",
    "        print(f\"Output tokens: {output_tokens} | Cost for output: ${output_tokens * 0.00375 / 1000:.6f}\")\n",
    "        print(f\"Total cost for the request and response using {model_name}: ${total_cost:.6f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
